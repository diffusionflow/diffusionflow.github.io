<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <script>let thunk=()=>{let e=e=>e.trim(),t=e=>e.innerText,n=e=>{let t=e.split(" "),n=t.slice(0,-1).join(" ");return[t.at(-1),n]},a=Array.from(document.getElementsByClassName("author")).map(t).map(e).map(n),i=a[0][0],o=(Array.from(document.getElementsByClassName("affiliation")).filter(e=>"P"===e.nodeName).map(t).map(e),"Diffusion Meets Flow Matching: Two Sides of the Same Coin");{let e=a.map(e=>`${e[0]}, ${e[1]}`).join(" and "),t=`\n@inproceedings{${(i+"2025"+o.split(" ").slice(0,3).join("")).replace(" ","").replace(/[\p{P}$+<=>^`|~]/gu,"").toLowerCase().trim()},\n  author = {${e}},\n  title = {${o}},\n  year = {2024},\n  url  = {${window.location.href}}\n}\n  `.trim();document.getElementById("bibtex-box").innerText=t}{let e=a.map(e=>e[0]),t=`\n${e=e.length>2?e[0]+", et al.":2==e.length?e[0]+" & "+e[1]:e[0]}, "${o}", ICLR Blogposts, 2025.\n`.trim();document.getElementById("bibtex-academic-attribution").innerText=t}};document.addEventListener("readystatechange",function(){"complete"===document.readyState&&thunk()});</script> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Diffusion Meets Flow Matching</title> <meta name="author" content=" "> <meta name="description" content="Flow matching and diffusion models are two popular frameworks in generative modeling. Despite seeming similar, there is some confusion in the community about their exact connection. In this post, we aim to clear up this confusion and show that &lt;i&gt;diffusion models and Gaussian flow matching are the same&lt;/i&gt;, although different model specifications can lead to different network outputs and sampling schedules. This is great news, it means you can use the two frameworks interchangeably."> <meta name="keywords" content="diffusion models, flow matching"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/twotrees.jpg"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://diffusionflow.github.io/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> <style type="text/css">.fake-img{background:#bbb;border:1px solid rgba(0,0,0,0.1);box-shadow:0 0 4px rgba(0,0,0,0.1);margin-bottom:12px}.fake-img p{font-family:monospace;color:white;text-align:left;margin:12px 0;text-align:center;font-size:16px}</style> <d-front-matter> <script async type="text/json">{
      "title": "Diffusion Meets Flow Matching: Two Sides of the Same Coin",
      "description": "Flow matching and diffusion models are two popular frameworks in generative modeling. Despite seeming similar, there is some confusion in the community about their exact connection. In this post, we aim to clear up this confusion and show that <i>diffusion models and Gaussian flow matching are the same</i>, although different model specifications can lead to different network outputs and sampling schedules. This is great news, it means you can use the two frameworks interchangeably.",
      "published": "December 2, 2024",
      "authors": [
        {
          "author": "Ruiqi Gao",
          "authorURL": "https://ruiqigao.github.io/",
          "affiliations": [
            {
              "name": "Google DeepMind",
              "url": ""
            }
          ]
        },
        {
          "author": "Emiel Hoogeboom",
          "authorURL": "https://ehoogeboom.github.io/",
          "affiliations": [
            {
              "name": "",
              "url": ""
            }
          ]
        },
        {
          "author": "Jonathan Heek",
          "authorURL": "https://scholar.google.nl/citations?user=xxQzqVkAAAAJ&hl=nl",
          "affiliations": [
            {
              "name": "",
              "url": ""
            }
          ]
        },
        {
          "author": "Valentin De Bortoli",
          "authorURL": "https://vdeborto.github.io/",
          "affiliations": [
            {
              "name": "",
              "url": ""
            }
          ]
        },
        {
          "author": "Kevin P. Murphy",
          "authorURL": "https://scholar.google.com/citations?user=MxxZkEcAAAAJ&hl=en",
          "affiliations": [
            {
              "name": "",
              "url": ""
            }
          ]
        },
        {
          "author": "Tim Salimans",
          "authorURL": "https://scholar.google.nl/citations?user=w68-7AYAAAAJ&hl=en",
          "affiliations": [
            {
              "name": "",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script> </d-front-matter> </head> <body class="fixed-top-nav"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="//">Diffusion Meets Flow Matching</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="post distill"> <d-title> <h1>Diffusion Meets Flow Matching: Two Sides of the Same Coin</h1> <p>Flow matching and diffusion models are two popular frameworks in generative modeling. Despite seeming similar, there is some confusion in the community about their exact connection. In this post, we aim to clear up this confusion and show that <i>diffusion models and Gaussian flow matching are the same</i>, although different model specifications can lead to different network outputs and sampling schedules. This is great news, it means you can use the two frameworks interchangeably.</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div><a href="#overview">Overview</a></div> <div><a href="#sampling">Sampling</a></div> <div><a href="#training">Training</a></div> <div><a href="#diving-deeper-into-samplers">Diving deeper into samplers</a></div> <div><a href="#sde-and-ode-perspective">SDE and ODE perspective</a></div> <div><a href="#closing-takeaways">Closing takeaways</a></div> </nav> </d-contents> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/2025-04-28-distill-example/twotrees-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/2025-04-28-distill-example/twotrees-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/2025-04-28-distill-example/twotrees-1400.webp"></source> <img src="/assets/img/2025-04-28-distill-example/twotrees.jpg" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>Flow matching has gained popularity recently, due to the simplicity of its formulation and the “straightness” of its induced sampling trajectories. This raises the commonly asked question:</p> <p align="center"><i>"Which is better, diffusion or flow matching?"</i></p> <p>As we will see, diffusion models and flow matching are <em>equivalent</em> (for the common special case that the source distribution used with flow matching corresponds to a Gaussian), so there is no single answer to this question. In particular, we will show how to convert one formalism to another. But why does this equivalence matter? Well, it allows you to mix and match techniques developed from the two frameworks. For example, after training a flow matching model, you can use either a stochastic or deterministic sampling method (contrary to the common belief that flow matching is always deterministic).</p> <p>We will focus on the most commonly used flow matching formalism with the optimal transport path <d-cite key="lipman2022flow"></d-cite>, which is closely related to rectified flow <d-cite key="liu2022flow"></d-cite> and stochastic interpolants <d-cite key="albergo2022building,albergo2023stochastic"></d-cite>. Our purpose is not to recommend one approach over another (both frameworks are valuable, each rooted in distinct theoretical perspectives, and it’s actually even more encouraging that they lead to the same algorithm in practice), but rather to help practitioners understand and feel confident about using these frameworks interchangeably, while understanding the true degrees of freedom one has when tuning the algorithm—regardless of what it’s called.</p> <p>Check this <a href="https://colab.research.google.com/drive/13lAveB3qwjkgyILWW-9qiOOSHG0U5_O6?usp=sharing" rel="external nofollow noopener noopener noreferrer" target="_blank">Google Colab</a> for code used to produce plots and animations in this post.</p> <h2 id="overview">Overview</h2> <p>We start with a quick overview of the two frameworks.</p> <h3 id="diffusion-models">Diffusion models</h3> <p>A diffusion process gradually destroys an observed datapoint \(\bf{x}\) (such as an image) over time \(t\), by mixing the data with Gaussian noise. The noisy data at time \(t\) is given by a forward process: \(\begin{equation} {\bf z}_t = \alpha_t {\bf x} + \sigma_t {\boldsymbol \epsilon}, \;\mathrm{where} \; {\boldsymbol \epsilon} \sim \mathcal{N}(0, {\bf I}). \label{eq:forward} \end{equation}\) \(\alpha_t\) and \(\sigma_t\) define the <strong>noise schedule</strong>. A noise schedule is called variance-preserving if \(\alpha_t^2 + \sigma_t^2 = 1\). The noise schedule is designed in a way such that \({\bf z}_0\) is close to the clean data, and \({\bf z}_1\) is close to a Gaussian noise.</p> <p>To generate new samples, we can “reverse” the forward process: We initialize the sample \({\bf z}_1\) from a standard Gaussian. Given the sample \({\bf z}_t\) at time step \(t\), we predict what the clean sample might look like with a neural network (a.k.a. denoiser model) \(\hat{\bf x} = \hat{\bf x}({\bf z}_t; t)\), and then we project it back to a lower noise level \(s\) with the same forward transformation:</p> <p>\(\begin{eqnarray} {\bf z}_{s} &amp;=&amp; \alpha_{s} \hat{\bf x} + \sigma_{s} \hat{\boldsymbol \epsilon},\\ \end{eqnarray}\) where \(\hat{\boldsymbol \epsilon} = ({\bf z}_t - \alpha_t \hat{\bf x}) / \sigma_t\). (Alternatively we can train a neural network to predict the noise \(\hat{\boldsymbol \epsilon}\).) We keep alternating between predicting the clean data, and projecting it back to a lower noise level until we get the clean sample. This is the DDIM sampler <d-cite key="song2020denoising"></d-cite>. The randomness of samples only comes from the initial Gaussian sample, and the entire reverse process is deterministic. We will discuss the stochastic samplers later.</p> <h3 id="flow-matching">Flow matching</h3> <p>In flow matching, we view the forward process as a linear interpolation between the data \({\bf x}\) and a noise term \(\boldsymbol \epsilon\): \(\begin{eqnarray} {\bf z}_t = (1-t) {\bf x} + t {\boldsymbol \epsilon}.\\ \end{eqnarray}\)</p> <p>This corresponds to the diffusion forward process if the noise is Gaussian (a.k.a. Gaussian flow matching) and we use the schedule \(\alpha_t = 1-t, \sigma_t = t\).</p> <p>Using simple algebra, we can derive that \({\bf z}_t = {\bf z}_{s} + {\bf u} \cdot (t - s)\) for \(s &lt; t\), where \({\bf u} = {\boldsymbol \epsilon} - {\bf x}\) is the “velocity”, “flow”, or “vector field”. Hence, to sample \({\bf z}_s\) given \({\bf z}_t\), we reverse time and replace the vector field with our best guess at time \(t\): \(\hat{\bf u} = \hat{\bf u}({\bf z}_t; t) = \hat{\boldsymbol \epsilon} - \hat{\bf x}\), represented by a neural network, to get</p> \[\begin{eqnarray} {\bf z}_{s} = {\bf z}_t + \hat{\bf u} \cdot (s - t).\\ \label{eq:flow_update} \end{eqnarray}\] <p>Initializing the sample \({\bf z}_1\) from a standard Gaussian, we keep getting \({\bf z}_s\) at a lower noise level than \({\bf z}_t\), until we obtain the clean sample.</p> <h3 id="comparison">Comparison</h3> <p>So far, we can already discern the similar essences in the two frameworks:</p> <div style="padding: 10px 10px 10px 10px; border-left: 6px solid #FFD700; margin-bottom: 20px;"> <p>1. <strong>Same forward process</strong>, if we assume that one end of flow matching is Gaussian, and the noise schedule of the diffusion model is in a particular form. </p> <p style="margin: 0;">2. <strong>"Similar" sampling processes</strong>: both follow an iterative update that involves a guess of the clean data at the current time step. (Spoiler: below we will show they are exactly the same!)</p> </div> <h2 id="sampling">Sampling</h2> <p>It is commonly thought that the two frameworks differ in how they generate samples: Flow matching sampling is deterministic with “straight” paths, while diffusion model sampling is stochastic and follows “curved paths”. Below, we clarify this misconception. We will focus on deterministic sampling first, since it is simpler, and will discuss the stochastic case later on.</p> <p>Imagine you want to use your trained denoiser model to transform random noise into a datapoint. Recall that the DDIM update is given by \({\bf z}_{s} = \alpha_{s} \hat{\bf x} + \sigma_{s} \hat{\boldsymbol \epsilon}\). Interestingly, by rearranging terms it can be expressed in the following formulation, with respect to several sets of network outputs and reparametrizations:</p> \[\begin{equation} \tilde{\bf z}_{s} = \tilde{\bf z}_{t} + \mathrm{Network \; output} \cdot (\eta_s - \eta_t) \\ \end{equation}\] <table> <thead> <tr> <th style="text-align: left">Network Output</th> <th style="text-align: right">Reparametrization</th> </tr> </thead> <tbody> <tr> <td style="text-align: left">\(\hat{\bf x}\)-prediction</td> <td style="text-align: right">\(\tilde{\bf z}_t = {\bf z}_t / \sigma_t\) and \(\eta_t = {\alpha_t}/{\sigma_t}\)</td> </tr> <tr> <td style="text-align: left">\(\hat{\boldsymbol \epsilon}\)-prediction</td> <td style="text-align: right">\(\tilde{\bf z}_t = {\bf z}_t / \alpha_t\) and \(\eta_t = {\sigma_t}/{\alpha_t}\)</td> </tr> <tr> <td style="text-align: left">\(\hat{\bf u}\)-flow matching vector field</td> <td style="text-align: right">\(\tilde{\bf z}_t = {\bf z}_t/(\alpha_t + \sigma_t)\) and \(\eta_t = {\sigma_t}/(\alpha_t + \sigma_t)\)</td> </tr> </tbody> </table> <p>Remember the flow matching update in Equation (4)? This should look similar. If we set the network output as \(\hat{\bf u}\) in the last line and let \(\alpha_t = 1- t\), \(\sigma_t = t\), we have \(\tilde{\bf z}_t = {\bf z}_t\) and \(\eta_t = t\), which is the flow matching update! More formally, the flow matching update is a Euler sampler of the sampling ODE (i.e., \(\mathrm{d}{\bf z}_t = \hat{\bf u} \mathrm{d}t\)), and with the flow matching noise schedule,</p> <div style="padding: 10px 10px 10px 10px; border-left: 6px solid #FFD700; margin-bottom: 20px;"> <p align="center" style="margin: 0;"><em>Diffusion with DDIM sampler == Flow matching sampler (Euler).</em></p> </div> <p>Some other comments on the DDIM sampler:</p> <ol> <li> <p>The DDIM sampler <em>analytically</em> integrates the reparametrized sampling ODE (i.e., \(\mathrm{d}\tilde{\bf z}_t = \mathrm{[Network \; output]}\cdot\mathrm{d}\eta_t\)) if the network output is a <em>constant</em> over time. Of course the network prediction is not constant, but it means the inaccuracy of DDIM sampler only comes from approximating the intractable integral of the network output (unlike the Euler sampler of the probability flow ODE <d-cite key="song2020score"></d-cite> which involves an additional linear term of \({\bf z}_t\)). The DDIM sampler can be considered a first-order Euler sampler of the repamemetrized sampling ODE, which has the same update rule for different network outputs. However, if one uses a higher-order ODE solver, the network output can make a difference, which means the \(\hat{\bf u}\) output proposed by flow matching can make a difference from diffusion models.</p> </li> <li> <p>The DDIM sampler is <em>invariant</em> to a linear scaling applied to the noise schedule \(\alpha_t\) and \(\sigma_t\), as scaling does not affect \(\tilde{\bf z}_t\) and \(\eta_t\). This is not true for other samplers e.g. Euler sampler of the probability flow ODE.</p> </li> </ol> <p>To validate Claim 2, we present the results obtained using several noise schedules, each of which follows a flow-matching schedule (\(\alpha_t = 1-t, \sigma_t = t\)) with different scaling factors. Feel free to change the slider below the figure. At the left end, the scaling factor is \(1\), which is exactly the flow matching schedule (FM), while at the right end, the scaling factor is \(1/[(1-t)^2 + t^2]\), which corresponds to a variance-preserving schedule (VP). We see that DDIM (and flow matching sampler) always gives the same final data samples, regardless of the scaling of the schedule. The paths bend in different ways as we are showing \({\bf z}_t\) (but not \(\tilde{\bf z}_t\)), which is scale-dependent along the path. For the Euler sampler of the probabilty flow ODE, the scaling makes a true difference: we see that both the paths and the final samples change.</p> <div class="l-page"> <iframe src="/assets/html/2025-04-28-distill-example/interactive_alpha_sigma.html" frameborder="0" scrolling="no" height="600px" width="100%"></iframe> </div> <p>Wait a second! People often say flow matching results in <em>straight</em> paths, but in the above figure, the sampling trajectories look <em>curved</em>.</p> <p>Well first, why do they say that? If the model would be perfectly confident about the data point it is moving to, the path from noise to data will be a straight line, with the flow matching noise schedule. Straight line ODEs would be great because it means that there is no integration error whatsoever. Unfortunately, the predictions are not for a single point. Instead they average over a larger distribution. And flowing <em>straight to a point != straight to a distribution</em>.</p> <p>In the interactive graph below, you can change the variance of the data distribution on the right hand side by the slider. Note how the variance preserving schedule is better (straighter paths) for wide distributions, while the flow matching schedule works better for narrow distributions.</p> <div class="l-page"> <iframe src="/assets/html/2025-04-28-distill-example/interactive_vp_vs_flow.html" frameborder="0" scrolling="no" height="600px" width="100%"></iframe> </div> <p>Finding such straight paths for real-life datasets like images is of course much less straightforward. But the conclusion remains the same: The optimal integration method depends on the data distribution.</p> <p>Two important takeaways from deterministic sampling:</p> <div style="padding: 10px 10px 10px 10px; border-left: 6px solid #FFD700; margin-bottom: 20px;"> <p>1. <strong>Equivalence in samplers</strong>: DDIM is equivalent to the flow matching sampler, and is invariant to a linear scaling to the noise schedule. </p> <p style="margin: 0;">2. <strong>Straightness misnomer</strong>: Flow matching schedule is only straight for a model predicting a single point. For realistic distributions, other schedules can give straighter paths.</p> </div> <h2 id="training">Training</h2> <p>Diffusion models <d-cite key="kingma2024understanding"></d-cite> are trained by estimating \(\hat{\bf x} = \hat{\bf x}({\bf z}_t; t)\), or alternatively \(\hat{\boldsymbol \epsilon} = \hat{\boldsymbol \epsilon}({\bf z}_t; t)\) with a neural net. Learning the model is done by minimizing a weighted mean squared error (MSE) loss: \(\begin{equation} \mathcal{L}(\mathbf{x}) = \mathbb{E}_{t \sim \mathcal{U}(0,1), \boldsymbol{\epsilon} \sim \mathcal{N}(0, \mathbf{I})} \left[ \textcolor{green}{w(\lambda_t)} \cdot \frac{\mathrm{d}\lambda}{\mathrm{d}t} \cdot \lVert\hat{\boldsymbol \epsilon} - {\boldsymbol \epsilon}\rVert_2^2 \right], \end{equation}\) where \(\lambda_t = \log(\alpha_t^2 / \sigma_t^2)\) is the log signal-to-noise ratio, and \(\textcolor{green}{w(\lambda_t)}\) is the <strong>weighting function</strong>, balancing the importance of the loss at different noise levels. The term \(\mathrm{d}\lambda / {\mathrm{d}t}\) in the training objective seems unnatural and in the literature is often merged with the weighting function. However, their separation helps <em>disentangle</em> the factors of training noise schedule and weighting function clearly, and helps emphasize the more important design choice: the weighting function.</p> <p>Flow matching also fits in the above training objective. Recall below is the conditional flow matching objective used by <d-cite key="lipman2022flow, liu2022flow"></d-cite> :</p> \[\begin{equation} \mathcal{L}_{\mathrm{CFM}}(\mathbf{x}) = \mathbb{E}_{t \sim \mathcal{U}(0,1), \boldsymbol{\epsilon} \sim \mathcal{N}(0, \mathbf{I})} \left[ \lVert \hat{\bf u} - {\bf u} \rVert_2^2 \right] \end{equation}\] <p>Since \(\hat{\bf u}\) can be expressed as a linear combination of \(\hat{\boldsymbol \epsilon}\) and \({\bf z}_t\), the CFM training objective can be rewritten as mean squared error on \({\boldsymbol \epsilon}\) with a specific weighting.</p> <h3 id="how-do-we-choose-what-the-network-should-output">How do we choose what the network should output?</h3> <p>Below we summarize several network outputs proposed in the literature, including a few versions used by diffusion models and the one used by flow matching. They can be derived from each other given the current data \({\bf z}_t\). One may see the training objective defined with respect to MSE of different network outputs in the literature. From the perspective of training objective, they all correspond to having some additional weighting in front of the \({\boldsymbol \epsilon}\)-MSE that can be absorbed in the weighting function.</p> <table> <thead> <tr> <th style="text-align: left">Network Output</th> <th style="text-align: center">Formulation</th> <th style="text-align: right">MSE on Network Output</th> </tr> </thead> <tbody> <tr> <td style="text-align: left">\(\hat{\boldsymbol \epsilon}\)-prediction</td> <td style="text-align: center">\(\hat{\boldsymbol \epsilon}\)</td> <td style="text-align: right">\(\lVert\hat{\boldsymbol{\epsilon}} - \boldsymbol{\epsilon}\rVert_2^2\)</td> </tr> <tr> <td style="text-align: left">\(\hat{\bf x}\)-prediction</td> <td style="text-align: center">\(\hat{\bf x} = ({\bf z}_t - \sigma_t \hat{\boldsymbol \epsilon}) / \alpha_t\)</td> <td style="text-align: right">\(\lVert\hat{\bf x} - {\bf x}\rVert_2^2 = e^{-\lambda} \lVert\hat{\boldsymbol \epsilon} - {\boldsymbol \epsilon}\rVert_2^2\)</td> </tr> <tr> <td style="text-align: left">\(\hat{\bf v}\)-prediction</td> <td style="text-align: center">\(\hat{\bf v} = \alpha_t \hat{\boldsymbol{\epsilon}} - \sigma_t \hat{\bf x}\)</td> <td style="text-align: right">\(\lVert\hat{\bf v} - {\bf v}\rVert_2^2 = \alpha_t^2(e^{-\lambda} + 1)^2 \lVert\hat{\boldsymbol \epsilon} - {\boldsymbol \epsilon}\rVert_2^2\)</td> </tr> <tr> <td style="text-align: left">\(\hat{\bf u}\)-flow matching vector field</td> <td style="text-align: center">\(\hat{\bf u} = \hat{\boldsymbol{\epsilon}} - \hat{\bf x}\)</td> <td style="text-align: right">\(\lVert\hat{\bf u} - {\bf u}\rVert_2^2 = (e^{-\lambda / 2} + 1)^2 \lVert\hat{\boldsymbol \epsilon} - {\boldsymbol \epsilon}\rVert_2^2\)</td> </tr> </tbody> </table> <p>In practice, however, the model output might make a difference. For example,</p> <ul> <li> <p>\(\hat{\boldsymbol \epsilon}\)-prediction can be problematic at high noise levels, because any error in \(\hat{\boldsymbol \epsilon}\) will get amplified in \(\hat{\bf x} = ({\bf z}_t - \sigma_t \hat{\boldsymbol \epsilon}) / \alpha_t\), as \(\alpha_t\) is close to 0. It means that small changes create a large loss under some weightings.</p> </li> <li> <p>Following the similar reason, \(\hat{\bf x}\)-prediction is problematic at low noise levels, because \({\bf x}\) as a target is not informative when added noise is small, and the error gets amplified in \(\hat{\boldsymbol \epsilon}\).</p> </li> </ul> <p>Therefore, a heuristic is to choose a network output that is a combination of \(\hat{\bf x}\)- and \(\hat{\boldsymbol \epsilon}\)-predictions, which applies to the \(\hat{\bf v}\)-prediction and the flow matching vector field \(\hat{\bf u}\).</p> <h3 id="how-do-we-choose-the-weighting-function">How do we choose the weighting function?</h3> <p>The weighting function is the most important part of the loss. It balances the importance of high frequency and low frequency components in perceptual data such as images, videos and audo <d-cite key="dieleman2024spectral,kingma2024understanding"></d-cite>. This is crucial, as certain high frequency components in those signals are not perceptible to humans, and thus it is better not to waste model capacity on them when the model capacity is limited. Viewing losses via their weightings, one can derive the following non-obvious result:</p> <div style="padding: 10px 10px 10px 10px; border-left: 6px solid #FFD700; margin-bottom: 20px;"> <p align="center" style="margin: 0;"><em>Flow matching weighting == diffusion weighting of ${\bf v}$-MSE loss + cosine noise schedule.</em></p> </div> <p>That is, the conditional flow matching objective in Equation (7) is the same as a commonly used setting in diffusion models! See Appendix D.2-3 in <d-cite key="kingma2024understanding"></d-cite> for a detailed derivation. Below we plot several commonly used weighting functions in the literature, as a function of \(\lambda\).</p> <div class="m-page"> <iframe src="/assets/html/2025-04-28-distill-example/weighting_functions.html" frameborder="0" scrolling="no" height="600px" width="100%"></iframe> </div> <p>The flow matching weighting (also \({\bf v}\)-MSE + cosine schdule weighting) decreases exponentially as \(\lambda\) increases. Empirically we find another interesting connection: The Stable Diffusion 3 weighting <d-cite key="esser2024scaling"></d-cite>, a reweighted version of flow matching, is very similar to the EDM weighting <d-cite key="karras2022elucidating"></d-cite> that is popular for diffusion models.</p> <h3 id="how-do-we-choose-the-training-noise-schedule">How do we choose the training noise schedule?</h3> <p>We discuss the training noise schedule last, as it should be the least important to training for the following reasons:</p> <ol> <li>The training loss is <em>invariant</em> to the training noise schedule. Specifically, the loss fuction can be rewritten as \(\mathcal{L}(\mathbf{x}) = \int_{\lambda_{\min}}^{\lambda_{\max}} w(\lambda) \mathbb{E}_{\boldsymbol{\epsilon} \sim \mathcal{N}(0, \mathbf{I})} \left[ \|\hat{\boldsymbol{\epsilon}} - \boldsymbol{\epsilon}\|_2^2 \right] \, d\lambda\), which is only related to the endpoints (\(\lambda_{\max}\), \(\lambda_{\min}\)), but not the schedule \(\lambda_t\) in between. In practice, one should choose \(\lambda_{\max}\), \(\lambda_{\min}\) such that the two ends are close enough to the clean data and Gaussian noise respectively. \(\lambda_t\) might still affect the variance of the Monte Carlo estimator of the training loss. A few heuristics have been proposed in the literature to automatically adjust the noise schedules over the course of training. <a href="https://sander.ai/2024/06/14/noise-schedules.html#adaptive" rel="external nofollow noopener noopener noreferrer" target="_blank">This blog post</a> has a nice summary.</li> <li>Similar to sampling noise schedule, the training noise schedule is invariant to a linear scaling, as one can easily apply a linear scaling to \({\bf z}_t\) and an unscaling at the network input to get the equivalence. The key defining property of a noise schedule is the log signal-to-noise ratio \(\lambda_t\).</li> <li>One can choose completely different noise schedules for training and sampling, based on distinct heuristics: For training, it is desirable to have a noise schedule that minimizes the variance of the Monte Carlo estimator, whereas for sampling the noise schedule is more related to the discretization error of the ODE / SDE sampling trajectories and the model curvature.</li> </ol> <h3 id="summary">Summary</h3> <p>A few takeaways for training of diffusion models / flow matching:</p> <div style="padding: 10px 10px 10px 10px; border-left: 6px solid #FFD700; margin-bottom: 20px;"> <p>1. <strong>Equivalence in weightings</strong>: The weighting function is important for training, which balances the importance of different frequency components of perceptual data. Flow matching weightings coincidentlly match commonly used diffusion training weightings in the literature. </p> <p>2. <strong>Insignificance of training noise schedule</strong>: The noise schedule is far less important to the training objective, but can affect the training efficiency.</p> <p style="margin: 0;">3. <strong>Difference in network outputs</strong>: The network output proposed by flow matching is new, which nicely balances $\hat{\bf x}$- and $\hat{\epsilon}$-prediction, similar to $\hat{\bf v}$-prediction.</p> </div> <h2 id="diving-deeper-into-samplers">Diving deeper into samplers</h2> <p>In this section, we discuss different kinds of samplers in more detail.</p> <h3 id="reflow-operator">Reflow operator</h3> <p>The Reflow operation in flow matching connects noise and data points in a straight line. One can obtain these (data, noise) pairs by running a deterministic sampler from noise. A model can then be trained to directly predict the data given the noise avoiding the need for sampling. In the diffusion literature, the same approach was the one of the first distillation techniques <d-cite key="luhman2021knowledge"></d-cite>.</p> <h3 id="deterministic-sampler-vs-stochastic-sampler">Deterministic sampler vs. stochastic sampler</h3> <p>So far we have just discussed the deterministic sampler of diffusion models or flow matching. An alternative is to use stochastic samplers such as the DDPM sampler <d-cite key="ho2020denoising"></d-cite>.</p> <p>Performing one DDPM sampling step going from $\lambda_t$ to $\lambda_t + \Delta\lambda$ is exactly equivalent to performing one DDIM sampling step to $\lambda_t + 2\Delta\lambda$, and then renoising to $\lambda_t + \Delta\lambda$ by doing forward diffusion. That is, the renoising by doing forward diffusion reverses exactly half the progress made by DDIM. To see this, let’s take a look at a 2D example. Starting from the same mixture of Gaussians distribution, we can take either a small DDIM sampling step with the sign of the update reversed (left), or a small forward diffusion step (right):</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/2025-04-28-distill-example/particle_movement.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/2025-04-28-distill-example/particle_movement.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/2025-04-28-distill-example/particle_movement.gif-1400.webp"></source> <img src="/assets/img/2025-04-28-distill-example/particle_movement.gif" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>For individual samples, these updates behave quite differently: the reversed DDIM update consistently pushes each sample away from the modes of the distribution, while the diffusion update is entirely random. However, when aggregating all samples, the resulting distributions after the updates are identical. Consequently, if we perform a DDIM sampling step (without reversing the sign) followed by a forward diffusion step, the overall distribution remains unchanged from the one prior to these updates.</p> <p>The fraction of the DDIM step to undo by renoising is a hyperparameter which we are free to choose (i.e. does not have to be exact half of the DDIM step), and which has been called the level of <em>churn</em> by <d-cite key="karras2022elucidating"></d-cite>. Interestingly, the effect of adding churn to our sampler is to diminish the effect on our final sample of our model predictions made early during sampling, and to increase the weight on later predictions. This is shown in the figure below:</p> <div class="l-page" style="display: flex; justify-content: center; align-items: center;"> <iframe src="/assets/html/2025-04-28-distill-example/churn.html" frameborder="0" scrolling="no" height="600px" width="80%"></iframe> </div> <p>Here we ran different samplers for 100 sampling steps using a cosine noise schedule and \(\hat{\bf v}\)-prediction <d-cite key="salimansprogressive"></d-cite>. Ignoring nonlinear interactions, the final sample produced by the sampler can be written as a weighted sum of predictions \(\hat{\bf v}_t\) made during sampling and a Gaussian noise \({\bf e}\): \({\bf z}_0 = \sum_t h_t \hat{\bf v}_t + \sum_t c_t {\bf e}\). The weights \(h_t\) of these predictions are shown on the y-axis for different diffusion times \(t\) shown on the x-axis. DDIM results in an equal weighting of \(\hat{\bf v}\)-predictions for this setting, as shown in <d-cite key="salimansprogressive"></d-cite>, whereas DDPM puts more emphasis on predictions made towards the end of sampling. Also see <d-cite key="lu2022dpm"></d-cite> for analytic expressions of these weights in the \(\hat{\bf x}\)- and \(\hat{\boldsymbol \epsilon}\)-predictions.</p> <h2 id="sde-and-ode-perspective">SDE and ODE Perspective</h2> <p>We’ve observed the practical equivalence between diffusion models and flow matching algorithms. Here, we formally describe the equivalence of the forward and sampling processes using ODE and SDE, as a completeness in theory. </p> <h3 id="diffusion-models-1">Diffusion models</h3> <p>The forward process of diffusion models which gradually destroys a data over time can be described by the following stochastic differential equation (SDE):</p> \[\begin{equation} \mathrm{d} {\bf z}_t = f_t {\bf z}_t \mathrm{d} t + g_t \mathrm{d} {\bf z} , \end{equation}\] <p>where \(\mathrm{d} {\bf z}\) is an <em> infinitesimal Gaussian</em> (formally, a Brownian motion). $f_t$ and $g_t$ decide the noise schedule. The generative process is given by the reverse of the forward process, whose formula is given by</p> \[\begin{equation} \mathrm{d} {\bf z}_t = \left( f_t {\bf z}_t - \frac{1+ \eta_t^2}{2}g_t^2 \nabla \log p_t({\bf z_t}) \right) \mathrm{d} t + \eta_t g_t \mathrm{d} {\bf z} , \end{equation}\] <p>where $\nabla \log p_t$ is the <em>score</em> of the forward process. </p> <p>Note that we have introduced an additional parameter $\eta_t$ which controls the amount of stochasticity at inference time. This is related to the <em>churn</em> parameter introduced before. When discretizing the backward process we recover DDIM in the case $\eta_t = 0$ and DDPM in the case $\eta_t = 1$.</p> <h3 id="flow-matching-1">Flow matching</h3> <p>The interpolation between \({\bf x}\) and \({\boldsymbol \epsilon}\) in flow matching can be described by the following ordinary differential equation (ODE):</p> \[\begin{equation} \mathrm{d}{\bf z}_t = {\bf u}_t \mathrm{d}t. \end{equation}\] <p>Assuming the interpolation is \({\bf z}_t = \alpha_t {\bf x} + \sigma_t {\boldsymbol \epsilon}\), then \({\bf u}_t = \dot{\alpha}_t {\bf x} + \dot{\sigma}_t {\boldsymbol \epsilon}\).</p> <p>The generative process is simply reversing the ODE in time, and replacing \({\bf u}_t\) by its conditional expectation with respect to \({\bf z}_t\). This is a specific case of <em>stochastic interpolants</em><d-cite key="albergo2022building,albergo2023stochastic"></d-cite>, in which case it can be generalized to an SDE:</p> <p>\(\begin{equation} \mathrm{d} {\bf z}_t = ({\bf u}_t - \frac{1}{2} \varepsilon_t^2 \nabla \log p_t({\bf z_t})) \mathrm{d} t + \varepsilon_t \mathrm{d} {\bf z}, \end{equation}\) where \(\varepsilon_t\) controls the amount of stochasticity at inference time.</p> <h3 id="equivalence-of-the-two-frameworks">Equivalence of the two frameworks</h3> <p>Both frameworks are defined by three hyperparameters respectively: $f_t, g_t, \eta_t$ for diffusion, and $\alpha_t, \sigma_t, \varepsilon_t$ for flow matching. We can show the equivalence by deriving one set of hyperparameters from the other. From diffusion to flow matching:</p> \[\alpha_t = \exp\left(\int_0^t f_s \mathrm{d}s\right) , \quad \sigma_t = \left(\int_0^t g_s^2 \exp\left(-2\int_0^s f_u \mathrm{d}u\right) \mathrm{d} s\right)^{1/2} , \quad \varepsilon_t = \eta_t g_t .\] <p>From flow matching to diffusion:</p> \[f_t = \partial_t \log(\alpha_t) , \quad g_t^2 = 2 \alpha_t \sigma_t \partial_t (\sigma_t / \alpha_t) , \quad \eta_t = \varepsilon_t / (2 \alpha_t \sigma_t \partial_t (\sigma_t / \alpha_t))^{1/2} .\] <p>In summary, aside from training considerations and sampler selection, diffusion and Gaussian flow matching exhibit no fundamental differences.</p> <h2 id="closing-takeaways">Closing takeaways</h2> <p>If you’ve read this far, hopefully we’ve convinced you that diffusion models and Gaussian flow matching are equivalent. However, we highlight two new model specifications that Gaussian flow matching brings to the field:</p> <ul> <li> <strong>Network output</strong>: Flow matching proposes a vector field parametrization of the network output that is different from the ones used in diffusion literature. The network output can make a difference when higher-order samplers are used. It may also affect the training dynamics.</li> <li> <strong>Sampling noise schedule</strong>: Flow matching leverages a simple sampling noise schedule \(\alpha_t = 1-t\) and \(\sigma_t = t\), with the same update rule as DDIM.</li> </ul> <p>It would be interesting to investigate the importance of these two model specifications empirically in different real world applications, which we leave to future work. It is also an exciting research area to apply flow matching to more general cases where the source distribution is non-Gaussian, e.g. for more structured data like protein <d-cite key="bose2023se"></d-cite>.</p> <h2 id="acknowledgements">Acknowledgements</h2> <p>Thanks to our colleagues at Google DeepMind for fruitful discussions. In particular, thanks to Sander Dieleman, Ben Poole and Aleksander Hołyński.</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> </div> <d-article id="bibtex-container" class="related highlight"> For attribution in academic contexts, please cite this work as <pre id="bibtex-box">
        PLACEHOLDER FOR BIBTEX
  </pre> </d-article> <d-bibliography src="/assets/bibliography/2025-04-28-distill-example.bib"></d-bibliography> <script src="https://utteranc.es/client.js" repo="iclr-blogposts/2025" issue-term="pathname" theme="github-light" crossorigin="anonymous" async> </script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> </body> </html>